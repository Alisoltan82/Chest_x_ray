{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1179509,"sourceType":"datasetVersion","datasetId":669956},{"sourceId":7837917,"sourceType":"datasetVersion","datasetId":4594517},{"sourceId":7847287,"sourceType":"datasetVersion","datasetId":4601368},{"sourceId":7853482,"sourceType":"datasetVersion","datasetId":4606012}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-23T21:22:10.988516Z","iopub.execute_input":"2024-03-23T21:22:10.989205Z","iopub.status.idle":"2024-03-23T21:22:24.266965Z","shell.execute_reply.started":"2024-03-23T21:22:10.989150Z","shell.execute_reply":"2024-03-23T21:22:24.265527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install monai","metadata":{"execution":{"iopub.status.busy":"2024-03-23T21:22:24.269324Z","iopub.execute_input":"2024-03-23T21:22:24.270020Z","iopub.status.idle":"2024-03-23T21:22:42.338881Z","shell.execute_reply.started":"2024-03-23T21:22:24.269975Z","shell.execute_reply":"2024-03-23T21:22:42.337762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nimport os\nfrom tqdm.autonotebook import tqdm\nimport cv2\nfrom pathlib import Path\nimport pydicom as dicom\nfrom fastai import *\nfrom fastai.vision.all import *\nimport matplotlib.pyplot as plt\nfrom monai.config import print_config\nfrom monai.config import print_config , KeysCollection\nfrom monai.utils import first , set_determinism\nfrom monai.transforms import (\n    Compose,\n    LoadImage,\n    LoadImaged,\n    EnsureChannelFirst,\n    EnsureChannelFirstd,\n    ToTensor,\n    ToTensord,\n    ScaleIntensityRange,\n    ScaleIntensityRanged,\n    ThresholdIntensity,\n    ThresholdIntensityd,\n    SaveImaged,\n    Spacingd,\n    CropForegroundd,\n    Orientationd,\n    AsDiscrete,\n    RandCropByPosNegLabeld,\n    DivisiblePadd,\n    Resized,\n    RandFlipd,\n    RandRotate90d,\n    RandShiftIntensityd\n\n\n\n\n)\n\nprint_config()","metadata":{"execution":{"iopub.status.busy":"2024-03-23T21:22:42.340238Z","iopub.execute_input":"2024-03-23T21:22:42.340620Z","iopub.status.idle":"2024-03-23T21:23:53.794424Z","shell.execute_reply.started":"2024-03-23T21:22:42.340584Z","shell.execute_reply":"2024-03-23T21:23:53.791847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nmy_secret = user_secrets.get_secret('wandb')\nwandb.login(key = my_secret)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/rsnapneumoniadetectionchallenge/stage_2_train_labels.csv/stage_2_train_labels.csv')\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(df['Target'] , return_counts = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nor_weight = 1/20672\npn_weight = 1/9555","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['patientId'].drop_duplicates(inplace = True)\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HOME = os.getcwd()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_PATH = Path('/kaggle/input/rsnapneumoniadetectionchallenge/stage_2_train_images')\nout_path = Path('train').mkdir(parents = True , exist_ok = True)\nval = Path('valid').mkdir(parents = True , exist_ok = True)\nsums , sums_squared = 0,0\ntrain_path = Path('./train')\nvalid_path = Path('./valid')\n\n\ntrain_size = 15000 * 0.8\nfor i,j in enumerate(tqdm(df['patientId'][:15000])):\n    \n    fn = df['patientId'].iloc[i]\n    label = df['Target'].iloc[i]\n    \n    img_path = ROOT_PATH/fn\n    img_path = img_path.with_suffix('.dcm')\n    img = dicom.dcmread(img_path).pixel_array / 255\n    img_r = cv2.resize(img , (224,224)).astype(np.float16)\n    save_path = train_path/f'{str(label)}'\n    save_path.mkdir(parents=True, exist_ok=True)\n    val_path = valid_path/f'{str(label)}'\n    val_path.mkdir(parents=True, exist_ok=True)\n    \n    if i <=train_size:\n         np.save(save_path/fn ,img_r )\n    else:\n         np.save(val_path/fn ,img_r )\n            \n            \n    normalizer = 224*224 #new image dims\n    if i <= train_size:\n        sums += np.sum(img_r)/normalizer\n        sums_squared += (img_r **2).sum() / normalizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = sums / train_size\nprint(f'train images mean = {mean}')\n\nstd = np.sqrt((sums_squared/train_size) - mean**2)\nprint(f'train images standard deviation = {std}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn , optim, Tensor, manual_seed, argmax\nimport torchvision\nfrom torchvision import transforms\nimport torchmetrics\nimport torch.nn.functional as F\nfrom glob import glob\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2024-03-23T21:23:53.796869Z","iopub.execute_input":"2024-03-23T21:23:53.797660Z","iopub.status.idle":"2024-03-23T21:23:55.626074Z","shell.execute_reply.started":"2024-03-23T21:23:53.797622Z","shell.execute_reply":"2024-03-23T21:23:55.624921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean = mean , std = std ),\n    transforms.RandomAffine(degrees = (-5,5) , translate = (0, 0.05) , scale = (0.9 , 1.1) ),\n    transforms.RandomResizedCrop(size = (224,224) , scale = (0.5 , 1.0), antialias = True)\n    \n])\n\n\nval_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean = mean , std = std),\n    \n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_file(path):\n    return np.load(path).astype(np.float32)\n\ntrain_dataset = torchvision.datasets.DatasetFolder('/kaggle/working/train/' ,\n                                                   loader = load_file ,\n                                                   extensions = 'npy' ,\n                                                   transform = train_transforms)\n\nval_dataset = torchvision.datasets.DatasetFolder('/kaggle/working/valid/' ,\n                                                   loader = load_file ,\n                                                   extensions = 'npy' ,\n                                                   transform = val_transforms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , axis = plt.subplots(3,3,figsize = (9,10))\nfor i in range(3):\n    for j in range(3):\n        random_idx = np.random.randint(0 , 300)\n        img , label = train_dataset[random_idx]\n        axis[i][j].imshow(img[0] , cmap = 'bone')\n        axis[i][j].set_title(label)\nplt.show();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler\n\nscaler = GradScaler()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2024-03-23T21:23:55.627308Z","iopub.execute_input":"2024-03-23T21:23:55.627720Z","iopub.status.idle":"2024-03-23T21:23:56.097862Z","shell.execute_reply.started":"2024-03-23T21:23:55.627642Z","shell.execute_reply":"2024-03-23T21:23:56.096399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.resnet18(pretrained = True)\nfor params in zip( model.layer1.parameters() , model.layer2.parameters(), model.layer3.parameters()):\n    for param in params:\n        param.requires_grad = False\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method' : 'random'\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = {\n    'name' : 'val_accuracy',\n    'goal': 'maximize'\n}\n\nsweep_config['metric'] = metric","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters = {\n    'optimizer' : {\n        'values' : ['adam', 'adamw'  ,'sgd']\n\n}}\n\nsweep_config['parameters'] = parameters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.log(1e-4) , np.log(1e-2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters.update({\n    'learning_rate' : {\n        'distribution': 'log_uniform',\n        'min': -9.2,\n        'max': -4.6\n    },\n    'pos_weight' : {\n        'values' : [2,3]\n\n    },\n    'batch_size':{\n        'values': [16 , 32 , 64]\n    }\n})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pprint\n\npprint.pprint(sweep_config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep = sweep_config , project = 'xray_sweep_4')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sweep model building\n\nclass PneumoniaModel(pl.LightningModule):\n    \n    def __init__(self , optimizer = 'adam' , lr = 0.001 , pos_weight = 2 ):\n        super().__init__()\n        \n        #Model\n        self.model = torchvision.models.resnet18()\n        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.model.fc = torch.nn.Linear(in_features=512, out_features=1, bias=True)\n        \n        \n#         for params in zip(self.model.layer1.parameters() , self.model.layer2.parameters(), self.model.layer3.parameters()):\n#             for param in params:\n#                 param.requires_grad = False\n\n            \n\n        self.save_hyperparameters()\n        \n        \n        #optim\n        self.lr = lr\n        self.optimizer = torch.optim.Adam(self.model.parameters() , lr = lr)\n        \n        #loss\n        self.pos_weight = pos_weight\n        self.loss = torch.nn.BCEWithLogitsLoss(pos_weight = torch.tensor(pos_weight))\n    \n        \n        #Metrics\n        self.train_acc = torchmetrics.Accuracy(task = 'binary' )\n        self.val_acc = torchmetrics.Accuracy(task = 'binary')\n        self.test_acc = torchmetrics.Accuracy(task = 'binary')\n#         self.f1_score = torchmetrics.F1Score(task = 'binary')\n        self.precision = torchmetrics.classification.BinaryPrecision()\n        self.recall = torchmetrics.classification.BinaryRecall()\n#         self.sensitivity = torchmetrics.classification.BinarySpecificityAtSensitivity(min_sensitivity = 0.5)\n        \n        \n        \n    def forward(self , data):\n        pred = self.model(data)\n        return pred\n    \n    def training_step(self, batch , batch_idx , config = None):\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)[:,0]\n        loss = self.loss(pred, label)\n        accuracy = self.train_acc(pred,label)\n#         f1 = self.f1_score(pred,label)\n        self.config = wandb.config\n        self.log_dict({'train_accuracy': accuracy , 'train_loss': loss}\n                      ,on_step = False ,on_epoch = True , prog_bar = True)\n\n\n        return loss\n        \n        \n    def validation_step(self, batch , batch_idx):\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)[:,0]\n        loss = self.loss(pred, label)\n        accuracy = self.val_acc(pred,label)\n#         f1 = self.f1_score(pred,label)\n        precision = self.precision(pred,label)\n        recall = self.recall(pred,label)\n#         sensitivity = self.sensitivity(pred,label.int())\n        self.log_dict({'val_loss': loss ,'val_accuracy': accuracy,'precision': precision , 'recall': recall}\n                      ,on_step = False ,on_epoch = True , prog_bar = True)\n        \n#         if batch_idx % 5 == 0:\n#             x_ray = x_ray[:8]\n#             grid = torchvision.utils.make_grid(x_ray.view(-1,1,224,224))\n\n\n\n        return loss\n    \n\n    \n    def test_step(self, batch , batch_idx):\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)[:,0]\n        loss = self.loss(pred, label)\n        self.log('test_loss', loss , on_epoch = True)\n    \n\n    \n    def configure_optimizers(self):\n        return [self.optimizer]\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pytorch_lightning.loggers import WandbLogger","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sweep building\n\ndef sweep_iteration():\n    wandb.init()\n    wandb_logger = WandbLogger()\n    \n    model = PneumoniaModel(optimizer = wandb.config.optimizer,\n                          lr = wandb.config.learning_rate,\n                          pos_weight = wandb.config.pos_weight)\n    \n    #loaders\n    batch_size = wandb.config.batch_size\n    train_loader = torch.utils.data.DataLoader(train_dataset , batch_size = batch_size , num_workers = 6 , shuffle = True)\n    val_loader = torch.utils.data.DataLoader(val_dataset , batch_size = batch_size , num_workers = 6 )\n    \n    trainer = pl.Trainer( logger = wandb_logger,\n                        max_epochs = 15)\n    \n    trainer.fit(model , train_loader,val_loader)\n    trainer.validate(model , val_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.agent(sweep_id , function = sweep_iteration)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nnum_workers = 4\n\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset , batch_size = batch_size , num_workers = num_workers , shuffle = True)\nval_loader = torch.utils.data.DataLoader(val_dataset , batch_size = batch_size , num_workers = num_workers )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model building\n\nclass PneumoniaModel(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n        self.model = torchvision.models.resnet18(pretrained = True)\n        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.model.fc = torch.nn.Linear(in_features=512, out_features=1, bias=True)\n        self.save_hyperparameters()\n\n        self.optimizer = torch.optim.SGD(self.model.parameters() , lr = 0.0033)\n        pos_weights = 1\n        self.loss = torch.nn.BCEWithLogitsLoss(pos_weight = torch.tensor(pos_weights))\n\n        self.train_acc = torchmetrics.Accuracy(task = 'binary' )\n        self.val_acc = torchmetrics.Accuracy(task = 'binary')\n        self.test_acc = torchmetrics.Accuracy(task = 'binary')\n        self.f1_score = torchmetrics.F1Score(task = 'binary')\n        self.conf_m = torchmetrics.ConfusionMatrix(task = 'binary')\n    def forward(self , data):\n        pred = self.model(data)\n        return pred\n    \n    def training_step(self, batch , batch_idx , config = None):\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)[:,0]\n        loss = self.loss(pred, label)\n        accuracy = self.train_acc(pred,label)\n        f1 = self.f1_score(pred,label)\n        self.config = wandb.config\n        self.log_dict({'train_accuracy': accuracy , 'train_loss': loss}\n                      ,on_step = False ,on_epoch = True , prog_bar = True)\n\n\n        return loss\n        \n        \n    def validation_step(self, batch , batch_idx):\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)[:,0]\n        loss = self.loss(pred, label)\n        accuracy = self.val_acc(pred,label)\n        f1 = self.f1_score(pred,label)\n        matrix = self.conf_m(pred,label)\n        self.log_dict({'val_loss': loss ,'val_accuracy': accuracy,'val_F1score': f1}\n                      ,on_step = False ,on_epoch = True , prog_bar = True)\n        \n#         if batch_idx % 1000 == 0:\n#             x_ray = x_ray[:8]\n#             grid = torchvision.utils.make_grid(x_ray.view(-1,1,224,224))\n\n\n\n        return loss\n    \n\n    \n    def test_step(self, batch , batch_idx):\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)[:,0]\n        loss = self.loss(pred, label)\n        self.log('test_loss', loss , on_epoch = True)\n    \n\n    \n    def configure_optimizers(self):\n        return [self.optimizer]\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = PneumoniaModel()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wandb.init(project = 'Pneumonia_exp')\ncheckpoint_callback = ModelCheckpoint(monitor = 'val_accuracy' , save_top_k = 10 , mode = 'max'\n                                      , filename ='sample-xray-{epoch:02d}-{val_loss:.2f}'  )\n\nwandb_logger = WandbLogger(log_model=\"all\" , save_dir = './L06ogs' )\ntrainer = pl.Trainer( logger = wandb_logger , callbacks = checkpoint_callback , min_epochs = 20 ,max_epochs = 100 ,log_every_n_steps = 1 ,\n                     fast_dev_run = False , enable_model_summary = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit( model , train_loader, val_loader )\ntrainer.validate(model , val_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torchvision.models.efficientnet_b3()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model building\n\nclass PneumoniaModeleff(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n        self.model  = torchvision.models.efficientnet_b3(pretrained=False)\n        self.model.features[0][0] = torch.nn.Conv2d(1, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        self.model.classifier[-1] = torch.nn.Linear(in_features=1536, out_features=1, bias=True)\n        self.model.features[0][1] = torch.nn.BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n        self.save_hyperparameters()\n\n        self.optimizer = torch.optim.Adam(self.model.parameters() , lr = 0.001)\n        pos_weights = 2\n        self.loss = torch.nn.BCEWithLogitsLoss(pos_weight = torch.tensor(pos_weights))\n\n        self.train_acc = torchmetrics.Accuracy(task = 'binary' )\n        self.val_acc = torchmetrics.Accuracy(task = 'binary')\n        self.test_acc = torchmetrics.Accuracy(task = 'binary')\n        self.f1_score = torchmetrics.F1Score(task = 'binary')\n        self.conf_m = torchmetrics.ConfusionMatrix(task = 'binary')\n        \n    def forward(self , data):\n        pred = self.model(data)\n        return pred\n    \n    def training_step(self, batch , batch_idx):\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)[:,0]\n        loss = self.loss(pred, label)\n        accuracy = self.train_acc(pred,label)\n        f1 = self.f1_score(pred,label)\n        self.log_dict({'train_accuracy': accuracy , 'train_loss': loss}\n                      ,on_step = False ,on_epoch = True , prog_bar = True)\n\n\n        return loss\n        \n        \n    def validation_step(self, batch , batch_idx):\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)[:,0]\n        loss = self.loss(pred, label)\n        accuracy = self.val_acc(pred,label)\n        f1 = self.f1_score(pred,label)\n        matrix = self.conf_m(pred,label)\n        self.log_dict({'val_loss': loss ,'val_accuracy': accuracy,'val_F1score': f1}\n                      ,on_step = False ,on_epoch = True , prog_bar = True)\n        \n#         if batch_idx % 50 == 0:\n#             x_ray = x_ray[:8]\n#             grid = torchvision.utils.make_grid(x_ray.view(-1,1,224,224))\n#             self.logger.experiment.add_image('pneumonia',grid,self.global_step)\n#             self.log('confusion matrix' , matrix)\n\n\n        return loss\n    \n\n    \n    def test_step(self, batch , batch_idx):\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)[:,0]\n        loss = self.loss(pred, label)\n        self.log('test_loss', loss , on_epoch = True)\n    \n\n    \n    def configure_optimizers(self):\n        return [self.optimizer]\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-23T21:37:24.442939Z","iopub.execute_input":"2024-03-23T21:37:24.443495Z","iopub.status.idle":"2024-03-23T21:37:24.469534Z","shell.execute_reply.started":"2024-03-23T21:37:24.443452Z","shell.execute_reply":"2024-03-23T21:37:24.468101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(monitor = 'val_accuracy' , save_top_k = 10 , mode = 'max'\n                                      , filename ='xray-{epoch:02d}-{val_loss:.2f}'  )\n\nwandb_logger = WandbLogger(log_model=\"all\" , save_dir = './L02ogs' )\ntrainer = pl.Trainer( logger = wandb_logger , callbacks = checkpoint_callback , min_epochs = 20 ,max_epochs = 50,log_every_n_steps = 1 ,\n                     fast_dev_run = False , enable_model_summary = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !wget 'https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b5-86493f6b.pth'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2 = PneumoniaModeleff()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit( model_2 , train_loader, val_loader )\ntrainer.validate(model_2 , val_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = PneumoniaModeleff.load_from_checkpoint('/kaggle/input/eff-model/eff_model.ckpt')\ntorch.save(model.state_dict() , 'eff_state_dict.pth')\ntorch.save(model , 'effmodel.pth' )\nmodel.eval()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T21:59:08.657558Z","iopub.execute_input":"2024-03-23T21:59:08.659009Z","iopub.status.idle":"2024-03-23T21:59:09.428825Z","shell.execute_reply.started":"2024-03-23T21:59:08.658951Z","shell.execute_reply":"2024-03-23T21:59:09.427477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-03-23T21:44:14.027517Z","iopub.execute_input":"2024-03-23T21:44:14.028006Z","iopub.status.idle":"2024-03-23T21:44:14.197050Z","shell.execute_reply.started":"2024-03-23T21:44:14.027972Z","shell.execute_reply":"2024-03-23T21:44:14.193463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/kaggle/working/effmodel.pt')\nmodel.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nlabels = []\n\nwith torch.no_grad():\n    for data,label in tqdm(val_dataset):\n        data = data.to(device).float().unsqueeze(0)\n        pred = torch.sigmoid(model(data)[0].cpu())\n        preds.append(pred)\n        labels.append(label)\n    \npreds = torch.tensor(preds)\nlabels = torch.tensor(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = torchmetrics.Accuracy(task = 'binary')(preds,labels)\nprecision = torchmetrics.Precision(task = 'binary')(preds,labels)\nrecall = torchmetrics.Recall(task = 'binary')(preds,labels)\nmatrix = torchmetrics.ConfusionMatrix(task = 'binary' ,num_classes = 2)(preds,labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'precision = {precision}')\nprint(f'recall = {recall}')\nprint(f'accuracy = {acc}')\nprint(f'matrix = {matrix}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.heatmap(matrix , annot = True , fmt=\".1f\" , xticklabels = True  , yticklabels = True )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = PneumoniaModel.load_from_checkpoint('/kaggle/input/resmodel/res_model.ckpt')\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nlabels = []\n\nwith torch.no_grad():\n    for data,label in tqdm(val_dataset):\n        data = data.to(device).float().unsqueeze(0)\n        pred = torch.sigmoid(model(data)[0].cpu())\n        preds.append(pred)\n        labels.append(label)\n    \npreds = torch.tensor(preds)\nlabels = torch.tensor(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = torchmetrics.Accuracy(task = 'binary')(preds,labels)\nprecision = torchmetrics.Precision(task = 'binary')(preds,labels)\nrecall = torchmetrics.Recall(task = 'binary')(preds,labels)\nmatrix = torchmetrics.ConfusionMatrix(task = 'binary' ,num_classes = 2)(preds,labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'precision = {precision}')\nprint(f'recall = {recall}')\nprint(f'accuracy = {acc}')\nprint(f'matrix = {matrix}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(matrix , annot = True , fmt=\".1f\" )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nlabels = []\n\nwith torch.no_grad():\n    for data,label in tqdm(val_dataset):\n        data = data.to(device).float().unsqueeze(0)\n        pred = torch.sigmoid(model(data)[0].cpu())\n        print(pred)\n        preds.append(pred)\n        labels.append(label)\n        break\n    \npreds = torch.tensor(preds)\nlabels = torch.tensor(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = torchmetrics.Accuracy(task = 'binary')(preds,labels)\nprecision = torchmetrics.Precision(task = 'binary')(preds,labels)\nrecall = torchmetrics.Recall(task = 'binary')(preds,labels)\nmatrix = torchmetrics.ConfusionMatrix(task = 'binary' ,num_classes = 2)(preds,labels)\n\nprint(f'precision = {precision}')\nprint(f'recall = {recall}')\nprint(f'accuracy = {acc}')\nprint(f'matrix = {matrix}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(matrix , annot = True , fmt=\".1f\" )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PneumoniaFetModel(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.model = torchvision.models.resnet18(pretrained = True)\n        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.model.fc = torch.nn.Linear(in_features=512, out_features=1, bias=True)\n        \n        self.feature_map = torch.nn.Sequential(*list(self.model.children())[:-2]) #-2 includes the last avg poo;ing and the last fc layers\n        \n    def forward(self,data):\n        #feature extraxtion\n        feature_map = self.feature_map(data) #fitting the model without the last 2 layers to the data\n        av_pool_out = torch.nn.functional.adaptive_avg_pool2d(input = feature_map , output_size = (1,1))\n        av_pool_flattened = torch.flatten(av_pool_out) #512 flat\n\n        #normal prediction\n        pred = self.model.fc(av_pool_flattened)\n            \n        return pred , feature_map","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_feat = PneumoniaFetModel.load_from_checkpoint('/kaggle/input/resmodel/res_model.ckpt' , strict = False)\nmodel_feat.eval();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_feat.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cam(model , img):\n    img.to(device)\n    model.to(device)\n    with torch.inference_mode():\n        pred, features = model(img.unsqueeze(0))\n        \n    features = features.reshape((512,49)) #features original shape 512,7,7 3d to 2d\n    weight_params = list(model.model.fc.parameters())[0] # zero to access fc layer weights only away from biases 512\n    weight = weight_params[0].detach()\n    \n    cam = torch.matmul(weight , features) # weight = 512 , features = 512,49 ----> 49 element vector\n    cam_img = cam.reshape(7,7).cpu()\n    \n    return cam_img , torch.sigmoid(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\ndef visualize(img , cam , pred):\n    img = img[0]    #removes channel dim\n    cam = transforms.functional.resize(cam.unsqueeze(0), (224,224))[0]\n    \n    fig , ax = plt.subplots(1,2 , figsize = (10,8))\n    ax[0].imshow(img , cmap = 'gray')\n    ax[1].imshow(img , cmap = 'gray')\n    ax[1].imshow(cam , alpha = 0.5 , cmap = 'inferno_r' )\n    \n    plt.title(pred > 0.5)\n    plt.savefig('x_ray_feat')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = val_dataset[-13][0] #only image without label\n\nact_map ,pred = cam(model_feat , img.cuda())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize(img , act_map , pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}